# -*- coding: utf-8 -*-
"""Bts-PyTorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rr0FkI0i9K7M8qrGuw7_IkgSGHka5rGY

reason for death:

model does not load(246/649mb)
UnpicklingError: invalid load key, '\x08'.
"""

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/ErenBalatkan/Bts-PyTorch
# %cd Bts-PyTorch

sh = """#!/bin/bash
fileid="14n3cTmaKGJHIhL0sBRaByuyPBDyntHZm"
filename="models/bts_latest"
curl -c ./cookie -s -L "https://drive.google.com/uc?export=download&id=${fileid}" > /dev/null
curl -Lb ./cookie "https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=${fileid}" -o ${filename}
"""

f = open("download_model.sh", "w")
f.write(sh)
f.close()

!sh download_model.sh

!ls -l

import BTS
import cv2
from matplotlib import pyplot as plt
import numpy as np
import torch

def load_model(model, path):
    dict = torch.load(path)

    model.current_epoch = dict["epoch"]
    model.bts.load_state_dict(dict["model_state_dict"])
    model.bts = model.bts.float().to("cpu")

model = BTS.BtsController()
#model.load_model("models/bts_latest")
load_model(model,"models/bts_latest")
model.eval()

img = cv2.resize(cv2.imread("sample_image.png"), (1216, 352)) # Must be multiple of 32
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # OpenCV loads images as BGR by default
plt.imshow(img)

prediction = model.predict(img, is_channels_first=False, normalize=True) # Dont forget to normalize images
plt.imshow(prediction) # Reminder : plt.imshow() automatically scales the values, it does a good job but some libraries dont

visual_depth_map = model.depth_map_to_rgbimg(prediction) # A helper method for converting depth maps into 3 channel, 8 byte images
# images 3 channel, uint8 format are displayed without any scaling / normalization
plt.imshow(visual_depth_map)

torch.load("models/bts_latest")

!head models/bts_latest