# -*- coding: utf-8 -*-
"""Visualizing-CNNs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qvTzwXT5Hao7rc-epcd2MkgP0Oj-cB8m

###reason of death: 
* Cast layer in onnx, not supported in cv::dnn (we can register one, but pass special params) 
* %2294 : Tensor = onnx::Slice[axes=[0], ends=[9223372036854775807], starts=[2]](%2293)
"""

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/JunjH/Visualizing-CNNs-for-monocular-depth-estimation
# %cd Visualizing-CNNs-for-monocular-depth-estimation

from google.colab import drive
drive.mount('/content/drive')

!unzip "/content/drive/My Drive/pretrained_model.zip"

!unzip "/content/drive/My Drive/net_mask.zip"

!python test.py

!ls -l /content/Visualizing-CNNs-for-monocular-depth-estimation/
#!cat models/senet.py

import sys
sys.path.append('/content/Visualizing-CNNs-for-monocular-depth-estimation/models/')

import torch
import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn

import models
from models import resnet, densenet, senet, modules, net, resnet

import net_mask
import loaddata
import util
import numpy as np

import os

def define_model(encoder='resnet'):
    if encoder is 'resnet':
        original_model = resnet.resnet50(pretrained = True)
        Encoder = modules.E_resnet(original_model) 
        model = net.model(Encoder, num_features=2048, block_channel = [256, 512, 1024, 2048])
    if encoder is 'densenet':
        original_model = densenet.densenet161(pretrained=True)
        Encoder = modules.E_densenet(original_model)
        model = net.model(Encoder, num_features=2208, block_channel = [192, 384, 1056, 2208])
    if encoder is 'senet':
        original_model = senet.senet154(pretrained='imagenet')
        Encoder = modules.E_senet(original_model)
        model = net.model(Encoder, num_features=2048, block_channel = [256, 512, 1024, 2048])

    return model
   
def convert_to_onnx(net, output_name):
    input = torch.randn(1, 3, 224, 224)
    input_names = ['data']
    output_names = ['output']
    net.eval()
    torch.onnx.export(net, input, output_name, verbose=True, input_names=input_names, output_names=output_names,opset_version=9)

model_selection = 'senet'
model = define_model(encoder = model_selection)
original_model2 = net_mask.drn_d_22(pretrained=True)
model2 = net_mask.AutoED(original_model2)

#model = model.cuda()
#model2 = model2.cuda()
#model = torch.nn.DataParallel(model).cuda()
#model2 = torch.nn.DataParallel(model2).cuda()
dic = torch.load('./pretrained_model/model_' + model_selection)
print(dic.keys())
D2 = {}
for k in dic.keys():
   D2[k.replace("module.","",1)] = dic[k]
print(D2.keys())

model.load_state_dict(D2)
convert_to_onnx(model,"model.onnx")

"""
dic = torch.load('./net_mask/mask_' + model_selection)
print(dic.keys())
D2 = {}
for k in dic.keys():
   D2[k.replace("module.","")] = dic[k]
print(D2.keys())
model2.load_state_dict(D2)

convert_to_onnx(model2,"model2.onnx")
"""

import cv2

class CastLayer(object):
    def __init__(self, params, blobs):
        pass
    def getMemoryShapes(self, inputs):
        return inputs
    def forward(self, inputs):
        return [inputs[0].astype(np.int32)]

#cv2.dnn_registerLayer('Cast', CastLayer)
net = cv2.dnn.readNet("model.onnx")