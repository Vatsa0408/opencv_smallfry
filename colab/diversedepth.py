# -*- coding: utf-8 -*-
"""DiverseDepth.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ug6P3Wp_YO_V1ylTRlse2O8aUO1BQK6S
"""

# Commented out IPython magic to ensure Python compatibility.
# broken code !!!!
!git clone https://github.com/YvanYin/DiverseDepth
# %cd DiverseDepth

#%cd /content/DiverseDepth
!cp "/content/drive/My Drive/cv2_cuda/cv2.cpython-36m-x86_64-linux-gnu.so" .

!wget https://cloudstor.aarnet.edu.au/plus/s/ixWf3nTJFZ0YE4q/download -O resnext50_32x4d.pth

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/DiverseDepth
from lib.models.diverse_depth_model import RelDepthModel
from lib.utils.net_tools import load_ckpt
from lib.core.config import cfg
print("__ ", cfg.MODEL.ENCODER)

model = RelDepthModel()
model.eval()
"""checkpoint = torch.load("resnext50_32x4d.pth")
model_state_dict_keys = model.state_dict().keys()
checkpoint_state_dict_noprefix = strip_prefix_if_present(checkpoint['model_state_dict'], "module.")
if all(key.startswith('module.') for key in model_state_dict_keys):
    model.module.load_state_dict(checkpoint_state_dict_noprefix)
else:
    model.load_state_dict(checkpoint_state_dict_noprefix)
"""
#                                lateral_resnext50_32x4d_body_stride16():

2240/7

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/DiverseDepth
!ls  -f /content/DiverseDepth/lib/models/__pycache__/*
!rm  -f /content/DiverseDepth/lib/models/__pycache__/*
!ls  -f /content/DiverseDepth/lib/core/__pycache__/*
!rm  -f /content/DiverseDepth/lib/core/__pycache__/*
!ls  -f /content/DiverseDepth/lib/configs/__pycache__/*
!rm  -f /content/DiverseDepth/lib/configs/__pycache__/*

import torch.nn as nn
import torch


class BidirectionalLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(BidirectionalLSTM, self).__init__()
        self.rnn = nn.LSTM(input_size, hidden_size, bidirectional=True, batch_first=True)
        self.linear = nn.Linear(hidden_size * 2, output_size)

    def forward(self, input):
        self.rnn.flatten_parameters()
        recurrent, _ = self.rnn(input)
        b, T, h = recurrent.size()
        recurrent = recurrent.view(b*T, h)
        output = self.linear(recurrent)  # batch_size x T x output_size
        output = output.view(b, T, -1)
        return output


class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.SequenceModeling = nn.Sequential(
            BidirectionalLSTM(512, 512, 512),
            BidirectionalLSTM(512, 512, 512))

    def forward(self, input):
        contextual_feature = self.SequenceModeling(input)
        return contextual_feature


x = torch.rand(1, 65, 512).float().cpu()
model = Model()
model.eval()
torch.onnx.export(model, x, "ocr0811_1.onnx", verbose=True)

import cv2
net = cv2.dnn.readNetFromONNX('ocr0811_1.onnx')
net.setInput(x.numpy())
#res = net.forward()
#graph(%input.1 : Float(1:33280, 65:512, 512:1),