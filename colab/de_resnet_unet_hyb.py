# -*- coding: utf-8 -*-
"""DE_resnet_unet_hyb.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19vGjA3mKvQGm1upw2qx-K6Zau3CJDX27
"""

!pip install opencv-python==4.2.0.32

!pip install torch==1.3.0
import torch
torch.__version__

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/karoly-hars/DE_resnet_unet_hyb
# %cd DE_resnet_unet_hyb

import argparse
import cv2
import numpy as np
import torch
from network import ResnetUnetHybrid
import image_utils

img_path = "example_data/test_img0.jpg"
#img_path = "/content/DSC_0000007.jpg"

# switch to CUDA device if possible
#device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
device = "cpu" # for onnx export
print('Use GPU: {}'.format(str(device) != 'cpu'))
# load model
print('Loading model...')
model = ResnetUnetHybrid.load_pretrained(device=device)
model.eval()

# load image
img = cv2.imread(img_path)[..., ::-1]
img = image_utils.scale_image(img)
img = image_utils.center_crop(img)
inp = image_utils.img_transform(img)
inp = inp[None, :, :, :].to(device)
print(inp.shape)
# inference
print('Running the image through the network...')
output = model(inp)

# transform and plot the results
depth = output.cpu()[0].data.numpy()

def depth_to_grayscale(depth, max_dist=10.0):
    """Transform a prediction into a grayscale 8-bit image."""
    depth = np.transpose(depth, (1, 2, 0))
    depth[depth > max_dist] = max_dist
    depth = depth / max_dist

    depth = np.array(depth * 255.0, dtype=np.uint8)
    depth = cv2.resize(depth, (0,0), fx=2, fy=2)

    bgr_depth_img = cv2.cvtColor(depth, cv2.COLOR_GRAY2BGR)
    bgr_depth_img = np.clip(bgr_depth_img, 0, 255)
    return bgr_depth_img

from google.colab.patches import cv2_imshow
cv2_imshow(img)
pred = depth_to_grayscale(depth)
cv2_imshow(pred)
cv2.imwrite("pred.png",pred)

def convert_to_onnx(net, output_name):
    input = torch.randn(1, 3, 256, 320)
    input_names = ['data']
    output_names = ['output']
    net.eval()
    torch.onnx.export(net, input, output_name, verbose=True, input_names=input_names, output_names=output_names)

convert_to_onnx(model, "model.onnx")

#%cd ..
!ls -l

import cv2, numpy as np

img = cv2.imread("example_data/test_img0.jpg")

net = cv2.dnn.readNet("model.onnx")