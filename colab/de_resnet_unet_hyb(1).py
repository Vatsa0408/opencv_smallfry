# -*- coding: utf-8 -*-
"""DE_resnet_unet_hyb.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19vGjA3mKvQGm1upw2qx-K6Zau3CJDX27
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content
!git clone https://github.com/karoly-hars/DE_resnet_unet_hyb
# %cd DE_resnet_unet_hyb

"""torch infer"""

import cv2
import torch
from network import ResnetUnetHybrid
import image_utils


def predict_img(img_path):
    """Inference a single image."""
    # switch to CUDA device if possible
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    print('Use GPU: {}'.format(str(device) != 'cpu'))

    # load model
    print('Loading model...')
    model = ResnetUnetHybrid.load_pretrained(device=device)
    model.eval()

    # load image
    img = cv2.imread(img_path)[..., ::-1]
    img = image_utils.scale_image(img)
    img = image_utils.center_crop(img)
    inp = image_utils.img_transform(img)
    inp = inp[None, :, :, :].to(device)

    # inference
    print('Running the image through the network...')
    output = model(inp)

    # transform and plot the results
    output = output.cpu()[0].data.numpy()
    image_utils.show_img_and_pred(img, output)
    
predict_img("/content/DE_resnet_unet_hyb/example_data/test_img0.jpg")

"""onnx export"""

import numpy as np
import torch
import torch.nn as nn
import cv2
import os
from network import ResnetUnetHybrid, Bottleneck,ConConv,get_incoming_shape

# new_shape[axis] *= len(tensors)
#  when exported from onnx, will assert:
#   'inputs.size()' from getMemoryShapes() in cv::dnn::Net
#  seems we must not use math ops like multiplication
#   so let it try to infer the resp. dimension (-1)

def interleave(tensors, axis):
    old_shape = get_incoming_shape(tensors[0])
    if axis==2:
      new_shape = [1, old_shape[1], -1, old_shape[3]]
    elif axis==3:
      new_shape = [1, old_shape[1], old_shape[2], -1]
    
    # change the first element (batch_size to 1)
    #new_shape = [1] + new_shape[1:]
    # double 1 dimension
    #new_shape[axis] *= len(tensors)
    
    # pack the tensors on top of each other
    stacked = torch.stack(tensors, axis+1)
    #print(stacked.size())
    # reshape and return
    reshaped = stacked.reshape(new_shape)
    #print(reshaped.size())
    return reshaped
  



class UnpoolingAsConvolution(nn.Module):
    def __init__(self, inplanes, planes):
        super(UnpoolingAsConvolution, self).__init__()

        # interleaving convolutions
        self.conv_A = nn.Conv2d(in_channels=inplanes, out_channels=planes, kernel_size=(3, 3), stride=1, padding=1)
        self.conv_B = nn.Conv2d(in_channels=inplanes, out_channels=planes, kernel_size=(2, 3), stride=1, padding=0)
        self.conv_C = nn.Conv2d(in_channels=inplanes, out_channels=planes, kernel_size=(3, 2), stride=1, padding=0)
        self.conv_D = nn.Conv2d(in_channels=inplanes, out_channels=planes, kernel_size=(2, 2), stride=1, padding=0)

    def forward(self, x):
        output_a = self.conv_A(x)

        padded_b = nn.functional.pad(x, (1, 1, 0, 1))
        output_b = self.conv_B(padded_b)

        padded_c = nn.functional.pad(x, (0, 1, 1, 1))
        output_c = self.conv_C(padded_c)

        padded_d = nn.functional.pad(x, (0, 1, 0, 1))
        output_d = self.conv_D(padded_d)

        left = interleave([output_a, output_b], axis=2)
        right = interleave([output_c, output_d], axis=2)
        y = interleave([left, right], axis=3)
        return y



class UpProjection(nn.Module):
    def __init__(self, inplanes, planes):
        super(UpProjection, self).__init__()

        self.unpool_main = UnpoolingAsConvolution(inplanes, planes)
        self.unpool_res = UnpoolingAsConvolution(inplanes, planes)

        self.main_branch = nn.Sequential(
            self.unpool_main,
            nn.BatchNorm2d(planes),
            nn.ReLU(inplace=False),
            nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(planes)
        )

        self.residual_branch = nn.Sequential(
            self.unpool_res,
            nn.BatchNorm2d(planes),
        )

        self.relu = nn.ReLU(inplace=False)

    def forward(self, input_data):
        x = self.main_branch(input_data)
        res = self.residual_branch(input_data)
        x += res
        x = self.relu(x)
        return x

class MyNet(nn.Module):
    def __init__(self, block, layers):
        self.inplanes = 64

        # resnet layers
        super(MyNet, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)

        # additional up projection layers parts
        self.conv2 = nn.Conv2d(2048, 1024, 1, bias=True)
        self.bn2 = nn.BatchNorm2d(1024)

        self.up_proj1 = UpProjection(1024, 512)
        self.up_proj2 = UpProjection(512, 256)
        self.up_proj3 = UpProjection(256, 128)
        self.up_proj4 = UpProjection(128, 64)

        self.drop = nn.Dropout(0.5, False)
        self.conv3 = nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1, bias=True)
        
        # padding + concat for unet stuff
        self.con_conv1 = ConConv(1024, 512, 512)
        self.con_conv2 = ConConv(512, 256, 256)
        self.con_conv3 = ConConv(256, 128, 128)
        self.con_conv4 = ConConv(64, 64, 64)
  
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.normal_(m.weight, 0, 0.01)

            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

    def _make_layer(self, block, planes, blocks, stride=1):
        downsample = None
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                nn.Conv2d(self.inplanes, planes * block.expansion,
                          kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(planes * block.expansion),
            )

        layers = list()
        layers.append(block(self.inplanes, planes, stride, downsample))
        self.inplanes = planes * block.expansion
        for i in range(1, blocks):
            layers.append(block(self.inplanes, planes))

        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x_to_conv4 = self.relu(x)
        x = self.maxpool(x_to_conv4)

        x_to_conv3 = self.layer1(x)
        x_to_conv2 = self.layer2(x_to_conv3)
        x_to_conv1 = self.layer3(x_to_conv2)
        x = self.layer4(x_to_conv1)

        # additional layers
        x = self.conv2(x)
        x = self.bn2(x)

        # up project part
        x = self.up_proj1(x)
        x = self.con_conv1(x, x_to_conv1)

        x = self.up_proj2(x)
        x = self.con_conv2(x, x_to_conv2)

        x = self.up_proj3(x)
        x = self.con_conv3(x, x_to_conv3)

        x = self.up_proj4(x)
        x = self.con_conv4(x, x_to_conv4)

        x = self.drop(x)
        x = self.conv3(x)
        x = self.relu(x)
        return x

    @classmethod
    def load_pretrained(cls, device, load_path='hyb_net_weights.model'):
        model = cls(Bottleneck, [3, 4, 6, 3])

        # download the weights if they are not present
        if not os.path.exists(load_path):
            print('Downloading model weights...')
            os.system('wget https://www.dropbox.com/s/amad4ko9opi4kts/hyb_net_weights.model')

        model = model.to(device)
        model.load_state_dict(torch.load(load_path, map_location=device))

        return model

#model = ResnetUnetHybrid(Bottleneck, [3, 4, 6, 3]) #.load_pretrained(device=device)
model = MyNet.load_pretrained(device = "cpu")
#print(model)
def convert_to_onnx(net, output_name):
    input = torch.randn(1, 3, 256, 320)
    input_names = ['data']
    output_names = ['output']
    net.eval()
    torch.onnx.export(net, input, output_name, verbose=False, input_names=input_names, output_names=output_names)

convert_to_onnx(model, "bottle.onnx")
net = cv2.dnn.readNet("bottle.onnx")

!cp bottle.onnx "/content/drive/My Drive/DE_resnet_unet_hyb.onnx"

"""cv dnn infer"""

#@title
#%cd /content
import math
import cv2, numpy as np
from google.colab.patches import cv2_imshow
import image_utils

HEIGHT = 256
WIDTH = 320
def depth_to_grayscale(depth, max_dist=10.0):
    """Transform a prediction into a grayscale 8-bit image."""
    depth = np.transpose(depth, (1, 2, 0))
    depth[depth > max_dist] = max_dist
    depth = depth / max_dist

    depth = np.array(depth * 255.0*255, dtype=np.uint16)
    depth = cv2.resize(depth, (WIDTH, HEIGHT))

    #bgr_depth_img = cv2.cvtColor(depth, cv2.COLOR_GRAY2BGR)
    depth_img = np.clip(depth, 0, 255*255)
    return depth_img

def scale_image(img, scale=None):
    """Resize/scale an image. If a scale is not provided, scale it closer to HEIGHT x WIDTH."""
    # if scale is None, scale to the longer size
    if scale is None:
        scale = max(WIDTH / img.shape[1], HEIGHT / img.shape[0])

    new_size = (math.ceil(img.shape[1] * scale), math.ceil(img.shape[0] * scale))
    image = cv2.resize(img, new_size, interpolation=cv2.INTER_NEAREST)
    return image


def center_crop(img):
    """Center crop an image to HEIGHT x WIDTH."""
    corner = ((img.shape[0] - HEIGHT) // 2, (img.shape[1] - WIDTH) // 2)
    img = img[corner[0]:corner[0] + HEIGHT, corner[1]:corner[1] + WIDTH]
    return img


def img_transform(img):
    """Normalize an image."""
    data_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    img = data_transform(img)
    return img
 
#img_path = "example_data/test_img0.jpg"
img_path = "buikd2.jpg"
mean=[0.485, 0.456, 0.406]
std=[0.229, 0.224, 0.225]
org = cv2.imread(img_path)#[..., ::-1]
cv2_imshow(org)
img = scale_image(org)
img = center_crop(img)
img = image_utils.img_transform(img)
img = img.detach().numpy()
print(img.shape, img.dtype)
#inp = inp[None, :, :, :].to(device)
"""
omg = 2.0 * (org.astype(np.float32)/255.0) - 1.0
omg = scale_image(omg)
omg = center_crop(omg)
omg -= mean
omg /= std
#img = omg.transpose(2,0,1)
#cv2_imshow(omg)
print(img.shape, img.dtype)
"""

net = cv2.dnn.readNet("bottle.onnx")
blob = img.reshape(1,img.shape[0],img.shape[1],img.shape[2])
#blob = cv2.dnn.blobFromImage(img)#, 0.225, (WIDTH,HEIGHT), [0.485, 0.456, 0.406], False, True)
net.setInput(blob)
res = net.forward()
print(res.shape, res.dtype)
res = depth_to_grayscale(res[0,:,:,:])
#res = res[0,:,:,:].transpose((1,2,0)) * 255
#res = np.clip(res,0,255)
#res = cv2.resize(res,(org.shape[1],org.shape[0])).astype(np.uint8)
print(res.shape, res.dtype)
#print(res)
#res *= 255
draw = (res/255).astype(np.uint8)
cv2_imshow(draw)
cv2.imwrite("bottle.png", res)
"""
net.dumpToFile("bottle_dot.txt")
!dot bottle_dot.txt -Tpng -obottle_dot.png
#!head -c 5000 pose_dot.png
im=cv2.imread("bottle_dot.png")
print(np.shape(im))
cv2_imshow(im)
"""

"""##rebuild cv2"""

!pip uninstall opencv-python

# Commented out IPython magic to ensure Python compatibility.
# %cd /content
!git clone https://github.com/berak/opencv
# %cd opencv

# Commented out IPython magic to ensure Python compatibility.
!mkdir /content/opencv/build
# %cd /content/opencv/build
!cmake -DBUILD_SHARED_LIBS=OFF -DBUILD_TESTS=OFF -DBUILD_PERF_TESTS=OFF .. 
#-DBUILD_LIST="core,imgproc,dnn,imgcodecs,python3" ..

#!make clean
!make -j8 install

import sys
#sys.path = "/usr/local/lib/python3.6/dist-packages/"
#try:
import cv2
#except: pass

cv2.__version__
#print(cv2.getBuildInformation())

!pip install onnx

!python /usr/local/lib/python3.6/dist-packages/onnx/tools/net_drawer.py --input=model.onnx --output=onnx.dot

!dot onnx.dot -Tsvg -oonnx_dot.svg

import cv2
from google.colab.patches import cv2_imshow
#im = cv2.imread("onnx_dot.png")
#cv2_imshow(im)